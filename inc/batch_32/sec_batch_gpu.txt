2019-08-01 04:34:38.066947: step 5, loss = 9.37 (24.7 examples/sec; 1.297 sec/batch)
2019-08-01 04:34:44.590912: step 10, loss = 7.95 (24.6 examples/sec; 1.300 sec/batch)
2019-08-01 04:34:51.109412: step 15, loss = 7.01 (24.4 examples/sec; 1.311 sec/batch)
2019-08-01 04:34:57.624990: step 20, loss = 9.57 (24.5 examples/sec; 1.307 sec/batch)
2019-08-01 04:35:04.143488: step 25, loss = 6.96 (24.6 examples/sec; 1.303 sec/batch)
2019-08-01 04:35:10.680970: step 30, loss = 5.99 (24.6 examples/sec; 1.303 sec/batch)
2019-08-01 04:35:17.231188: step 35, loss = 6.66 (24.4 examples/sec; 1.312 sec/batch)
2019-08-01 04:35:23.790831: step 40, loss = 6.66 (24.4 examples/sec; 1.310 sec/batch)
2019-08-01 04:35:30.360403: step 45, loss = 6.68 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:35:36.900342: step 50, loss = 5.87 (24.5 examples/sec; 1.307 sec/batch)
2019-08-01 04:35:43.472189: step 55, loss = 7.41 (24.4 examples/sec; 1.314 sec/batch)
2019-08-01 04:35:50.036672: step 60, loss = 6.80 (24.4 examples/sec; 1.313 sec/batch)
2019-08-01 04:35:56.570575: step 65, loss = 7.00 (24.5 examples/sec; 1.305 sec/batch)
2019-08-01 04:36:03.128092: step 70, loss = 5.93 (24.4 examples/sec; 1.312 sec/batch)
2019-08-01 04:36:09.687330: step 75, loss = 6.45 (24.3 examples/sec; 1.316 sec/batch)
2019-08-01 04:36:16.234469: step 80, loss = 6.70 (24.6 examples/sec; 1.301 sec/batch)
2019-08-01 04:36:22.785045: step 85, loss = 6.00 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:36:29.339714: step 90, loss = 6.34 (24.3 examples/sec; 1.314 sec/batch)
2019-08-01 04:36:35.900524: step 95, loss = 6.02 (24.4 examples/sec; 1.314 sec/batch)
2019-08-01 04:36:42.447541: step 100, loss = 6.90 (24.4 examples/sec; 1.311 sec/batch)
2019-08-01 04:36:51.803846: step 105, loss = 6.37 (24.2 examples/sec; 1.320 sec/batch)
2019-08-01 04:36:58.380818: step 110, loss = 5.88 (24.5 examples/sec; 1.304 sec/batch)
2019-08-01 04:37:04.926150: step 115, loss = 7.18 (24.5 examples/sec; 1.306 sec/batch)
2019-08-01 04:37:11.453414: step 120, loss = 6.16 (24.5 examples/sec; 1.306 sec/batch)
2019-08-01 04:37:18.026245: step 125, loss = 5.93 (24.2 examples/sec; 1.325 sec/batch)
2019-08-01 04:37:24.559425: step 130, loss = 6.90 (24.5 examples/sec; 1.305 sec/batch)
2019-08-01 04:37:31.106509: step 135, loss = 6.21 (24.5 examples/sec; 1.304 sec/batch)
2019-08-01 04:37:37.659440: step 140, loss = 6.06 (24.4 examples/sec; 1.310 sec/batch)
2019-08-01 04:37:44.202085: step 145, loss = 6.74 (24.4 examples/sec; 1.313 sec/batch)
2019-08-01 04:37:50.779410: step 150, loss = 5.89 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:37:57.323388: step 155, loss = 6.05 (24.5 examples/sec; 1.307 sec/batch)
2019-08-01 04:38:03.861408: step 160, loss = 6.36 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:38:10.425573: step 165, loss = 6.42 (24.4 examples/sec; 1.310 sec/batch)
2019-08-01 04:38:16.963759: step 170, loss = 5.88 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:38:23.527482: step 175, loss = 6.00 (24.6 examples/sec; 1.303 sec/batch)
2019-08-01 04:38:30.055056: step 180, loss = 6.04 (24.5 examples/sec; 1.305 sec/batch)
2019-08-01 04:38:36.601833: step 185, loss = 6.17 (24.3 examples/sec; 1.314 sec/batch)
2019-08-01 04:38:43.152718: step 190, loss = 5.89 (24.4 examples/sec; 1.311 sec/batch)
2019-08-01 04:38:49.723302: step 195, loss = 6.44 (24.5 examples/sec; 1.308 sec/batch)
2019-08-01 04:38:56.274336: step 200, loss = 5.73 (24.4 examples/sec; 1.312 sec/batch)
2019-08-01 04:39:06.105817: step 205, loss = 7.05 (24.5 examples/sec; 1.304 sec/batch)
2019-08-01 04:39:12.668551: step 210, loss = 5.66 (24.4 examples/sec; 1.313 sec/batch)
2019-08-01 04:39:19.241594: step 215, loss = 5.71 (23.8 examples/sec; 1.343 sec/batch)
2019-08-01 04:39:25.769159: step 220, loss = 5.63 (24.6 examples/sec; 1.302 sec/batch)
2019-08-01 04:39:32.331933: step 225, loss = 5.73 (24.4 examples/sec; 1.311 sec/batch)
2019-08-01 04:39:38.880128: step 230, loss = 5.78 (24.4 examples/sec; 1.314 sec/batch)
2019-08-01 04:39:45.442041: step 235, loss = 6.34 (24.3 examples/sec; 1.315 sec/batch)
2019-08-01 04:39:51.970046: step 240, loss = 5.98 (24.6 examples/sec; 1.303 sec/batch)
2019-08-01 04:39:58.505797: step 245, loss = 6.19 (24.5 examples/sec; 1.304 sec/batch)
2019-08-01 04:40:05.076941: step 250, loss = 5.99 (24.3 examples/sec; 1.314 sec/batch)
2019-08-01 04:40:11.626272: step 255, loss = 5.69 (24.4 examples/sec; 1.314 sec/batch)
2019-08-01 04:40:18.164664: step 260, loss = 5.75 (24.6 examples/sec; 1.301 sec/batch)
2019-08-01 04:40:24.709854: step 265, loss = 5.79 (24.5 examples/sec; 1.307 sec/batch)
2019-08-01 04:40:31.273889: step 270, loss = 5.96 (24.4 examples/sec; 1.313 sec/batch)
2019-08-01 04:40:37.838106: step 275, loss = 6.50 (24.3 examples/sec; 1.317 sec/batch)
2019-08-01 04:40:44.383783: step 280, loss = 5.71 (24.5 examples/sec; 1.306 sec/batch)
2019-08-01 04:40:50.927667: step 285, loss = 5.76 (24.5 examples/sec; 1.307 sec/batch)
2019-08-01 04:40:57.477872: step 290, loss = 5.87 (24.5 examples/sec; 1.304 sec/batch)
2019-08-01 04:41:04.023152: step 295, loss = 6.11 (24.4 examples/sec; 1.309 sec/batch)
2019-08-01 04:41:10.567551: step 300, loss = 6.19 (24.7 examples/sec; 1.298 sec/batch)
2019-08-01 04:41:20.066977: step 305, loss = 6.26 (24.3 examples/sec; 1.316 sec/batch)
2019-08-01 04:41:26.645300: step 310, loss = 5.49 (24.4 examples/sec; 1.309 sec/batch)