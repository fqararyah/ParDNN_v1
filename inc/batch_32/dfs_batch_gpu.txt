2019-07-27 12:21:47.826662: step 5, loss = 12.04 (22.8 examples/sec; 1.401 sec/batch)
2019-07-27 12:21:54.792134: step 10, loss = 10.17 (23.0 examples/sec; 1.389 sec/batch)
2019-07-27 12:22:01.786990: step 15, loss = 8.58 (23.0 examples/sec; 1.394 sec/batch)
2019-07-27 12:22:08.720119: step 20, loss = 13.66 (23.1 examples/sec; 1.386 sec/batch)
2019-07-27 12:22:15.637386: step 25, loss = 8.26 (23.3 examples/sec; 1.372 sec/batch)
2019-07-27 12:22:22.603725: step 30, loss = 8.94 (23.0 examples/sec; 1.394 sec/batch)
2019-07-27 12:22:29.554246: step 35, loss = 6.72 (22.7 examples/sec; 1.408 sec/batch)
2019-07-27 12:22:36.497815: step 40, loss = 8.56 (23.0 examples/sec; 1.392 sec/batch)
2019-07-27 12:22:43.439596: step 45, loss = 5.81 (23.2 examples/sec; 1.376 sec/batch)
2019-07-27 12:22:50.367270: step 50, loss = 6.97 (23.1 examples/sec; 1.386 sec/batch)
2019-07-27 12:22:57.283342: step 55, loss = 7.26 (22.9 examples/sec; 1.397 sec/batch)
2019-07-27 12:23:04.213891: step 60, loss = 5.96 (23.1 examples/sec; 1.384 sec/batch)
2019-07-27 12:23:11.168267: step 65, loss = 6.28 (22.9 examples/sec; 1.399 sec/batch)
2019-07-27 12:23:18.114293: step 70, loss = 6.63 (23.0 examples/sec; 1.390 sec/batch)
2019-07-27 12:23:25.034918: step 75, loss = 7.06 (22.9 examples/sec; 1.395 sec/batch)
2019-07-27 12:23:31.973905: step 80, loss = 8.20 (23.2 examples/sec; 1.381 sec/batch)
2019-07-27 12:23:38.951850: step 85, loss = 6.63 (23.1 examples/sec; 1.385 sec/batch)
2019-07-27 12:23:45.884274: step 90, loss = 6.14 (23.1 examples/sec; 1.387 sec/batch)
2019-07-27 12:23:52.832666: step 95, loss = 6.36 (23.0 examples/sec; 1.393 sec/batch)
2019-07-27 12:23:59.777421: step 100, loss = 6.92 (23.2 examples/sec; 1.376 sec/batch)
2019-07-27 12:24:10.394112: step 105, loss = 6.32 (23.1 examples/sec; 1.388 sec/batch)
2019-07-27 12:24:17.347117: step 110, loss = 6.55 (23.0 examples/sec; 1.390 sec/batch)
2019-07-27 12:24:24.314476: step 115, loss = 5.97 (22.9 examples/sec; 1.396 sec/batch)
2019-07-27 12:24:31.263973: step 120, loss = 6.16 (23.0 examples/sec; 1.389 sec/batch)
2019-07-27 12:24:38.255879: step 125, loss = 5.95 (22.8 examples/sec; 1.404 sec/batch)
2019-07-27 12:24:45.206185: step 130, loss = 6.37 (23.1 examples/sec; 1.385 sec/batch)
2019-07-27 12:24:52.160870: step 135, loss = 5.78 (22.9 examples/sec; 1.398 sec/batch)
2019-07-27 12:24:59.159095: step 140, loss = 5.75 (23.0 examples/sec; 1.389 sec/batch)
2019-07-27 12:25:06.103630: step 145, loss = 6.06 (22.8 examples/sec; 1.402 sec/batch)
2019-07-27 12:25:13.067567: step 150, loss = 6.03 (23.2 examples/sec; 1.379 sec/batch)
2019-07-27 12:25:20.017348: step 155, loss = 6.03 (23.2 examples/sec; 1.378 sec/batch)
2019-07-27 12:25:26.963977: step 160, loss = 6.10 (22.8 examples/sec; 1.401 sec/batch)
2019-07-27 12:25:33.907475: step 165, loss = 5.74 (23.2 examples/sec; 1.377 sec/batch)
2019-07-27 12:25:40.850314: step 170, loss = 5.92 (23.1 examples/sec; 1.384 sec/batch)
2019-07-27 12:25:47.724482: step 175, loss = 6.07 (23.3 examples/sec; 1.375 sec/batch)
2019-07-27 12:25:54.614955: step 180, loss = 5.74 (23.2 examples/sec; 1.380 sec/batch)
2019-07-27 12:26:01.541272: step 185, loss = 6.79 (23.1 examples/sec; 1.385 sec/batch)
2019-07-27 12:26:08.526413: step 190, loss = 5.89 (22.9 examples/sec; 1.395 sec/batch)
2019-07-27 12:26:15.479707: step 195, loss = 5.81 (23.2 examples/sec; 1.380 sec/batch)
2019-07-27 12:26:22.482065: step 200, loss = 5.66 (22.6 examples/sec; 1.414 sec/batch)
2019-07-27 12:26:33.594999: step 205, loss = 5.65 (23.1 examples/sec; 1.387 sec/batch)
2019-07-27 12:26:40.539553: step 210, loss = 5.75 (23.2 examples/sec; 1.378 sec/batch)
2019-07-27 12:26:47.441330: step 215, loss = 6.49 (23.2 examples/sec; 1.381 sec/batch)
2019-07-27 12:26:54.389076: step 220, loss = 6.32 (23.0 examples/sec; 1.391 sec/batch)
2019-07-27 12:27:01.368668: step 225, loss = 6.15 (23.1 examples/sec; 1.387 sec/batch)
2019-07-27 12:27:08.296758: step 230, loss = 5.68 (23.0 examples/sec; 1.394 sec/batch)
2019-07-27 12:27:15.238758: step 235, loss = 5.86 (23.1 examples/sec; 1.388 sec/batch)
2019-07-27 12:27:22.201163: step 240, loss = 6.13 (23.0 examples/sec; 1.392 sec/batch)
2019-07-27 12:27:29.151810: step 245, loss = 5.82 (23.0 examples/sec; 1.392 sec/batch)
2019-07-27 12:27:36.121876: step 250, loss = 6.03 (22.9 examples/sec; 1.400 sec/batch)
2019-07-27 12:27:43.063098: step 255, loss = 5.92 (23.1 examples/sec; 1.382 sec/batch)
2019-07-27 12:27:50.051294: step 260, loss = 5.81 (22.8 examples/sec; 1.406 sec/batch)
2019-07-27 12:27:57.014786: step 265, loss = 5.78 (23.0 examples/sec; 1.390 sec/batch)
2019-07-27 12:28:03.917348: step 270, loss = 5.47 (23.5 examples/sec; 1.364 sec/batch)
2019-07-27 12:28:10.882397: step 275, loss = 6.34 (22.8 examples/sec; 1.403 sec/batch)
2019-07-27 12:28:17.840704: step 280, loss = 5.69 (22.8 examples/sec; 1.405 sec/batch)
2019-07-27 12:28:24.751857: step 285, loss = 5.64 (22.9 examples/sec; 1.396 sec/batch)
2019-07-27 12:28:31.687157: step 290, loss = 5.81 (22.9 examples/sec; 1.397 sec/batch)
2019-07-27 12:28:38.644931: step 295, loss = 5.90 (23.0 examples/sec; 1.394 sec/batch)
2019-07-27 12:28:45.551808: step 300, loss = 6.79 (23.1 examples/sec; 1.386 sec/batch)
2019-07-27 12:28:55.958804: step 305, loss = 5.90 (23.1 examples/sec; 1.388 sec/batch)
2019-07-27 12:29:02.944542: step 310, loss = 5.69 (23.0 examples/sec; 1.389 sec/batch)